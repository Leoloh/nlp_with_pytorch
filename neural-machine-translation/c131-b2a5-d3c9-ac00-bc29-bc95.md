# Evaluation for MT

번역기의 성능을 평가하는 방법은 크게 두 가지로 나눌 수 있습니다. 정성적(implicit) 평가와 정량적(explicit) 평가 방식입니다.

## 1. Implicit Evaluation

정성평가 방식은 보통 사람이 번역된 문장을 채점하는 형태로 이루어집니다. 사람은 선입견 등이 채점하는데 있어서 방해요소로 작용될 수 있기 때문에, 보통은 blind test를 통해서 채점합니다. 이를 위해서 여러개의 다른 알고리즘을 통해 (또는 경쟁사의) 여러 번역결과를 누구의 것인지 밝히지 않은 채, 채점하여 우열을 가립니다. 이 방식은 가장 정확하다고 할 수 있지만, 자원과 시간이 많이 드는 단점이 있습니다.

## 2. Explicit Evalution

위의 단점 때문에, 보통은 자동화 된 정량평가를 주로 수행합니다. 두 평가를 모두 주기적으로 수행하되, 정성평가의 평가 주기를 좀 더 길게 가져가거나, 무언가 확실한 성능의 jump가 이루어졌을 때 수행하는 편 입니다.

### a. Cross Entropy and Perplexity

Neural Machine Translation task도 기본적으로 어떤 단어를 pick 하는 작업이기 때문에 기본적으로 classification task에 속합니다. 따라서 ***Cross Entropy***를 Loss function으로 사용합니다. 

$$
H(p,q)=−\sum_{\forall x}p(x)\log{q(x)}
$$

위의 식은 기본 Cross Entropy 수식입니다. 이것을 우리의 번역 모델($$ M_\theta $$)에 적용하여 보면 아래와 같습니다.

$$
L=-\sum_{y \in Y, \hat{y} \backsim M_\theta}p(\hat{y})\log p(y)
$$

그런데 재미있는 점은 이전 챕터 Language Modeling 할 때 성능평가 지표로써 사용했던 Perplexity가 Cross Entropy와 밀접한 관련이 있다는 것 입니다.

### b. BLEU