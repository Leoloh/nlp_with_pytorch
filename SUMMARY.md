# Summary

* [소개글](README.md)
* [To Do & Milestone](to-do-and-milestone.md)
* Natural Language Processing with Deeplearning
  * [Intro](intro.md)
  * Why NLP important
  * Why NLP difficult
  * [Deeplearning](deeplearning.md)
  * [History](history.md)
* [PyTorch 소개](pytorch-c18c-ac1c.md)
  * [Intro](pytorch-c18c-ac1c/intro.md)
  * [How to install](pytorch-c18c-ac1c/how-to-install.md)
  * TorchText
  * Hello, PyTorch
* Word Sense Disambiguation \(WSD\)
  * [소개](word-sense-disambiguation.md)
  * Bayes Theorem
  * Naive Bayes
  * Selectional Preference
  * WordNet
* Preprocessing
  * [전처리 개요](c804-cc98-b9ac-ac1c-c694.md)
  * Corpus 수집
  * Cleaning corpus
  * Tokenization \(POS Tagging\)
* Word Embedding Vector
  * Intro
  * [One-hot encoding](one-hot-encoding.md)
  * [Previous methods](previous-methods.md)
  * [Word2Vec](word2vec.md)
  * GloVe
  * FastText
  * Advanced embedding
* RNN
  * RNN
  * LSTM
  * GRU
  * Gradient Clipping
* Sequential Problem
  * Intro
  * Hidden Markov Model
  * Conditional Random Field
  * Using Deeplearning
  * Named Entity Recognition
  * Part of Speech Tagging
* Language Modeling
  * [언어모델 개요](c5b8-c5b4-baa8-b378-ac1c-c694.md)
  * [Perpexity](perpexity.md)
  * [n-gram](n-gram.md)
  * [NNLM](nnlm.md)
* Text Classification
  * Intro
  * Using RNN
  * Using CNN
  * Using RNN
  * Unsupervised Text Classification
* Neural Machine Translation
  * [기계번역 개요 및 역사](ae30-acc4-bc88-c5ed-ac1c-c694-bc0f-c5ed-c0ac.md)
  * [성능 평가 방법](c131-b2a5-d3c9-ac00-bc29-bc95.md)
  * [Seq2seq](seq2seq.md)
  * [Attention](attention.md)
  * [Input Feeding](input-feeding.md)
  * Beam Search
  * Fully Convolutional Seq2seq
  * Transformer
* Reinforcement Learning for NMT
  * Intro
  * Policy Gradient
  * Supervised NMT
  * Unsupervised NMT
* Speech Recognition
  * Intro
  * Traditional methodology
  * End2end deeplearning
* Future Work
  * Memory Augmented Neural Network
    * Text Summarization
    * Quetional Answering

