# Summary

* [소개글](README.md)
* [To Do & Milestone](to-do-and-milestone.md)
* Natural Language Processing with Deeplearning
  * [Intro](nlp-with-deeplearning/ntro.md)
  * [Why NLP important](nlp-with-deeplearning/why-nlp-important.md)
  * [Why NLP difficult](nlp-with-deeplearning/why-nlp-difficult.md)
  * [Deeplearning](nlp-with-deeplearning/deeplearning.md)
  * [History](nlp-with-deeplearning/history.md)
* [PyTorch 소개](pytorch-c18c-ac1c.md)
  * [Intro](pytorch-c18c-ac1c/intro.md)
  * [How to install](pytorch-c18c-ac1c/how-to-install.md)
  * [TorchText](pytorch-c18c-ac1c/torchtext.md)
  * [Hello, PyTorch](pytorch-c18c-ac1c/hello-pytorch.md)
* [Word Sense Disambiguation \(WSD\)](word-sense-disambiguation-wsd.md)
  * [intro](word-sense-disambiguation-wsd/intro.md)
  * [Bayes Theorem](word-sense-disambiguation-wsd/bayes-theorem.md)
  * [Naive Bayes](word-sense-disambiguation-wsd/naive-bayes.md)
  * [Selectional Preference](word-sense-disambiguation-wsd/selectional-preference.md)
  * [WordNet](word-sense-disambiguation-wsd/wordnet.md)
* Preprocessing
  * [전처리 개요](c804-cc98-b9ac-ac1c-c694.md)
  * Corpus 수집
  * Cleaning corpus
  * Tokenization (POS Tagging)
* Word Embedding Vector
  * Intro
  * [One-hot encoding](one-hot-encoding.md)
  * [Previous methods](previous-methods.md)
  * [Word2Vec](word2vec.md)
  * GloVe
  * FastText
  * Advanced embedding
* RNN
  * RNN
  * LSTM
  * GRU
  * Gradient Clipping
* Sequential Problem
  * Intro
  * Hidden Markov Model
  * Conditional Random Field
  * Using Deeplearning
* Language Modeling
  * [언어모델 개요](c5b8-c5b4-baa8-b378-ac1c-c694.md)
  * [Perpexity](perpexity.md)
  * [n-gram](n-gram.md)
  * [NNLM](nnlm.md)
* Text Classification
  * [Intro](text-classification/intro.md)
  * Using RNN
  * Using CNN
  * Unsupervised Text Classification
* Neural Machine Translation
  * [기계번역 개요 및 역사](ae30-acc4-bc88-c5ed-ac1c-c694-bc0f-c5ed-c0ac.md)
  * [성능 평가 방법](c131-b2a5-d3c9-ac00-bc29-bc95.md)
  * [Seq2seq](seq2seq.md)
  * [Attention](attention.md)
  * [Input Feeding](input-feeding.md)
  * Beam Search
  * Fully Convolutional Seq2seq
  * Transformer
* Reinforcement Learning for NMT
  * Intro
  * Policy Gradient
  * Supervised NMT
  * Unsupervised NMT
* Speech Recognition
  * Intro
  * Traditional methodology
  * Seq2seq
* Advanced Topic
  * Memory Augmented Neural Network
    * Text Summarization
    * Quetional Answering

