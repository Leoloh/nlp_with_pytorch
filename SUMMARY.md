# Summary

* [소개글](README.md)
* [To Do & Milestone](to-do-and-milestone.md)
* Natural Language Processing with Deeplearning
  * [Intro](nlp-with-deeplearning/ntro.md)
  * [Why NLP important](nlp-with-deeplearning/why-nlp-important.md)
  * [Why NLP difficult](nlp-with-deeplearning/why-nlp-difficult.md)
  * [Deeplearning](nlp-with-deeplearning/deeplearning.md)
  * [History](nlp-with-deeplearning/history.md)
* PyTorch 소개
  * [Intro](pytorch-c18c-ac1c/intro.md)
  * [How to install](pytorch-c18c-ac1c/how-to-install.md)
  * [TorchText](pytorch-c18c-ac1c/torchtext.md)
  * [Hello, PyTorch](pytorch-c18c-ac1c/hello-pytorch.md)
* Word Sense Disambiguation \(WSD\)
  * [intro](word-sense-disambiguation-wsd/intro.md)
  * [Bayes Theorem](word-sense-disambiguation-wsd/bayes-theorem.md)
  * [Naive Bayes](word-sense-disambiguation-wsd/naive-bayes.md)
  * [Selectional Preference](word-sense-disambiguation-wsd/selectional-preference.md)
  * [WordNet](word-sense-disambiguation-wsd/wordnet.md)
* Preprocessing
  * [전처리 개요](preprocessing/c804-cc98-b9ac-ac1c-c694.md)
  * [Corpus 수집](preprocessing/collecting-corpus.md)
  * [Cleaning corpus](preprocessing/cleaning-corpus.md)
  * [Tokenization \(POS Tagging\)](preprocessing/tokenization.md)
* Word Embedding Vector
  * [Intro](word-embedding-vector/intro.md)
  * [One-hot encoding](word-embedding-vector/one-hot-encoding.md)
  * [Previous methods](word-embedding-vector/previous-methods.md)
  * [Word2Vec](word-embedding-vector/word2vec.md)
  * [GloVe](word-embedding-vector/glove.md)
  * [FastText](word-embedding-vector/fasttext.md)
  * [Advanced embedding](word-embedding-vector/advanced-embedding.md)
* Sequence Modeling
  * [Intro](sequential-problem/intro.md)
  * [Hidden Markov Model](sequential-problem/hmm.md)
  * [Conditional Random Field](sequential-problem/crf.md)
  * Recurrent Neural Network
    * [Vanila RNN](sequential-problem/rnn.md)
    * [Long Short Term Memory](rnn/lstm.md)
    * [Gated Recurrent Unit](rnn/gru.md)
    * [Gradient Clipping](rnn/gradient-clipping.md)
* Text Classification
  * [Intro](text-classification/intro.md)
  * [Using CNN](text-classification/cnn.md)
  * [Using RNN](text-classification/rnn.md)
  * [Unsupervised Text Classification](text-classification/unsupervised-text-classification.md)
* Language Modeling
  * [언어모델 개요](language-modeling/c5b8-c5b4-baa8-b378-ac1c-c694.md)
  * [n-gram](language-modeling/n-gram.md)
  * [Perpexity](language-modeling/perpexity.md)
  * [Neural Network Language Model](language-modeling/nnlm.md)
* Neural Machine Translation
  * [기계번역 개요 및 역사](neural-machine-translation/ae30-acc4-bc88-c5ed-ac1c-c694-bc0f-c5ed-c0ac.md)
  * [기계번역 pipeline](neural-machine-translation/pipeline.md)
  * [성능 평가 방법](neural-machine-translation/c131-b2a5-d3c9-ac00-bc29-bc95.md)
  * [Seq2seq](neural-machine-translation/seq2seq.md)
  * [Input Feeding](neural-machine-translation/input-feeding.md)
  * [Attention](neural-machine-translation/attention.md)
  * [Beam Search](neural-machine-translation/beam-search.md)
  * Productized NMT system
    * [Google's NMT](neural-machine-translation/gnmt.md)
    * [Edinburgh's NMT](neural-machine-translation/enmt.md)
  * Advanced Topic on NMT
    * [Using Monolingual Corpora](neural-machine-translation/mono.md)
    * [Multilingual NMT](neural-machine-translation/multilingual-nmt.md)
    * [Fully Convolutional Seq2seq](neural-machine-translation/fconv.md)
    * [Transformer](neural-machine-translation/transformer.md)
* Reinforcement Learning for NLP
  * [Intro](reinforcement-learning/intro.md)
  * [Policy Gradient](reinforcement-learning/policy-gradient.md)
  * [Supervised NMT](reinforcement-learning/supervised-nmt.md)
  * [Unsupervised NMT](reinforcement-learning/unsupervised-nmt.md)
* Speech Recognition
  * [Intro](speech-recognition/intro.md)
  * [Traditional methodology](speech-recognition/wfst.md)
  * [Seq2seq](speech-recognition/seq2seq.md)
* Advanced Topic
  * [Memory Augmented Neural Network](advanced-topic/memory-augmented-neural-network.md)
    * [Text Summarization](advanced-topic/text-summarization.md)
    * [Quetional Answering](advanced-topic/question-answering.md)
  * [Dynamic Memory Network](advanced-topic/dmn.md)

